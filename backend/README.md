# DocuAssist AI - Sistema RAG para DocumentaciÃ³n TÃ©cnica

## ğŸ“– DescripciÃ³n del Proyecto

**DocuAssist AI** es un sistema de **Retrieval-Augmented Generation (RAG)** diseÃ±ado para asistir a empleados y tÃ©cnicos de SERVIMAQ S.R.L. en la consulta de documentaciÃ³n tÃ©cnica y manuales de sistemas.

El sistema procesa preguntas en lenguaje natural sobre:
- **Equipos tÃ©cnicos**: Impresoras fiscales, balanzas electrÃ³nicas
- **Sistemas de software**: Manuales de configuraciÃ³n y uso de sistemas internos

### CaracterÃ­sticas Principales

- âœ… **ClasificaciÃ³n de intenciones** mediante LangGraph (greeting, documentation, out_of_scope)
- âœ… **Filtros inteligentes** por categorÃ­a, marca, modelo y tipo de documentaciÃ³n
- âœ… **Reranking** con Cohere Rerank v4 para mejorar relevancia
- âœ… **Prompts dinÃ¡micos** (genÃ©ricos para categorÃ­a vs especÃ­ficos para modelo)
- âœ… **Historial de conversaciones** persistente en SQLite
- âœ… **Guardrails pre-LLM** para detectar consultas prohibidas
- âœ… **API REST** documentada con FastAPI + Swagger
- âœ… **Tests automatizados** con pytest

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     USUARIO â†’ FastAPI (API REST)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    LANGGRAPH      â”‚
         â”‚  (Orquestador)    â”‚
         â”‚ classify_intent   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              â”‚              â”‚
    v              v              v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚conversationalâ”‚ â”‚documentationâ”‚ â”‚out_of_scope â”‚
â”‚    node     â”‚ â”‚    node     â”‚ â”‚    node      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚            â”‚            â”‚
         v            v            v
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚RETRIEVEâ”‚  â”‚ RERANK  â”‚  â”‚ GENERATE â”‚
    â”‚ChromaDBâ”‚  â”‚ Cohere  â”‚  â”‚  Cohere  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Stack TecnolÃ³gico

| Componente | TecnologÃ­a | DescripciÃ³n |
|------------|------------|-------------|
| **Backend** | FastAPI | Framework web con validaciÃ³n automÃ¡tica |
| **OrquestaciÃ³n** | LangGraph | GestiÃ³n de flujo conversacional con nodos |
| **LLM** | Cohere Command-R+ | GeneraciÃ³n de respuestas y clasificaciÃ³n |
| **Embeddings** | Cohere Embed Multilingual v3 | VectorizaciÃ³n de documentos y queries |
| **Reranking** | Cohere Rerank v4 | Refinamiento de resultados por relevancia |
| **Vector DB** | ChromaDB | Almacenamiento persistente de embeddings |
| **Base de Datos** | SQLite | Historial y usuarios |
| **Testing** | pytest | Tests automatizados |

---

## ğŸ“ Estructura del Proyecto

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                           # Entry point FastAPI
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ chat_router.py            # POST /chat
â”‚   â”‚       â””â”€â”€ history_router.py         # GET /history
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ config.py                     # ConfiguraciÃ³n (vacÃ­o)
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ base.py                       # Base declarativa SQLAlchemy
â”‚   â”‚   â”œâ”€â”€ session.py                    # SessionLocal y engine
â”‚   â”‚   â””â”€â”€ init_db.py                    # Script crear tablas
â”‚   â”œâ”€â”€ graph/
â”‚   â”‚   â”œâ”€â”€ chat_graph.py                 # DefiniciÃ³n del grafo LangGraph
â”‚   â”‚   â”œâ”€â”€ state.py                      # ChatState (TypedDict)
â”‚   â”‚   â””â”€â”€ nodes/
â”‚   â”‚       â”œâ”€â”€ classify_intent.py        # ClasificaciÃ³n de intenciones
â”‚   â”‚       â”œâ”€â”€ conversational_node.py    # Respuestas conversacionales
â”‚   â”‚       â”œâ”€â”€ documentation_node.py     # Pipeline RAG completo
â”‚   â”‚       â””â”€â”€ out_of_scope_node.py      # Respuestas fuera de alcance
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ retriever.py                  # BÃºsqueda semÃ¡ntica en ChromaDB
â”‚   â”‚   â”œâ”€â”€ reranker.py                   # Cohere Rerank
â”‚   â”‚   â”œâ”€â”€ generator.py                  # GeneraciÃ³n de respuestas
â”‚   â”‚   â”œâ”€â”€ query_rewriter.py             # Reescritura de queries
â”‚   â”‚   â”œâ”€â”€ chunking.py                   # DivisiÃ³n de texto
â”‚   â”‚   â””â”€â”€ prompts/
â”‚   â”‚       â”œâ”€â”€ intent_prompt.txt         # Prompt clasificaciÃ³n
â”‚   â”‚       â”œâ”€â”€ rag_prompt.txt            # Prompt especÃ­fico (con modelo)
â”‚   â”‚       â”œâ”€â”€ rag_prompt_generic.txt    # Prompt genÃ©rico (sin modelo)
â”‚   â”‚       â””â”€â”€ chat_prompt.txt           # Prompt conversacional
â”‚   â”œâ”€â”€ metadata/
â”‚   â”‚   â”œâ”€â”€ infer.py                      # ExtracciÃ³n de metadata desde PDFs
â”‚   â”‚   â”œâ”€â”€ infer_filters.py              # Inferencia desde pregunta
â”‚   â”‚   â”œâ”€â”€ model_inference.py            # Inferencia de modelo
â”‚   â”‚   â””â”€â”€ filter_resolution.py          # Merge de filtros
â”‚   â”œâ”€â”€ vectorstore/
â”‚   â”‚   â”œâ”€â”€ client.py                     # Cliente ChromaDB
â”‚   â”‚   â””â”€â”€ ingest.py                     # Script de ingesta de PDFs
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py                       # Interfaz base LLM
â”‚   â”‚   â””â”€â”€ cohere_client.py              # ImplementaciÃ³n Cohere
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ chat_service.py               # LÃ³gica principal de chat
â”‚   â”‚   â””â”€â”€ history_service.py            # GestiÃ³n de historial
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ history_model.py              # Modelo SQLAlchemy History
â”‚   â”œâ”€â”€ repository/
â”‚   â”‚   â””â”€â”€ history_repository.py         # Acceso a datos de historial
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ chat.py                       # ChatRequest (Pydantic)
â”‚   â”‚   â””â”€â”€ response.py                   # ChatResponse
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ rag_validation.py             # Validaciones de chunks
â”‚   â”œâ”€â”€ guardrails/
â”‚   â”‚   â””â”€â”€ pre_llm.py                    # DetecciÃ³n de consultas prohibidas
â”‚   â””â”€â”€ debug/
â”‚       â”œâ”€â”€ test_graph.py                 # Tests del grafo
â”‚       â””â”€â”€ test_retriever.py             # Tests del retriever
â”œâ”€â”€ chroma_db/                            # Base de datos vectorial (generada)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ pdfs/
â”‚       â”œâ”€â”€ tecnicos/                     # Manuales tÃ©cnicos de equipos
â”‚       â””â”€â”€ sistemas/                     # Manuales de software
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_chat_flow.py                 # Tests principales
â”œâ”€â”€ requirements.txt                      # Dependencias del proyecto
â””â”€â”€ README.md                             # Este archivo
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos

- Python 3.10+
- pip
- Cuenta en Cohere con API key

### Paso 1: Crear entorno virtual

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### Paso 2: Instalar dependencias

```bash
pip install -r requirements.txt
```

**Dependencias principales:**
```
fastapi
uvicorn
python-dotenv
langchain
langgraph
cohere
chromadb
pypdf
langchain-text-splitters
sqlalchemy
pytest
```

### Paso 3: Configurar variables de entorno

Crear archivo `.env` en la raÃ­z del proyecto:

```env
COHERE_API_KEY=tu_api_key_aqui
```

### Paso 4: Verificar la base de datos

El proyecto ya incluye `app.db` con la tabla `history` configurada. Si necesitas recrearla:

```bash
python -m app.db.init_db
```

### Paso 5: Preparar documentaciÃ³n (solo si usas tus propios PDFs)

**Nota:** El proyecto ya incluye ChromaDB pre-cargado en `chroma_db/`.

Si deseas usar tus propios documentos:
1. Coloca los PDFs en:
   - `data/pdfs/tecnicos/` â†’ Manuales tÃ©cnicos de equipos
   - `data/pdfs/sistemas/` â†’ Manuales de sistemas/software

2. Ejecuta la ingesta:
```bash
python -m app.vectorstore.ingest
```

Este proceso:
- Lee los PDFs de `data/pdfs/`
- Extrae metadata automÃ¡ticamente del nombre del archivo
- Genera embeddings con Cohere Embed v3
- Almacena en ChromaDB (`chroma_db/`)

---

## â–¶ï¸ EjecuciÃ³n

### Iniciar el servidor

```bash
uvicorn app.main:app --reload
```

El servidor estarÃ¡ disponible en: **http://localhost:8000**

### Endpoints disponibles

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| GET | `/health` | Health check del servicio |
| POST | `/chat` | Endpoint principal de chat |
| GET | `/history` | Obtener historial de conversaciones |
| GET | `/docs` | DocumentaciÃ³n Swagger interactiva |

### DocumentaciÃ³n interactiva

Swagger UI: **http://localhost:8000/docs**

---

## ğŸ§ª Testing

### Ejecutar tests

```bash
pytest tests/ -v
```

### Tests implementados

Los tests en [tests/test_chat_flow.py](tests/test_chat_flow.py) cubren:

```python
âœ… test_greeting()           # Saludo conversacional (sin RAG)
âœ… test_out_of_scope()       # Pregunta fuera de alcance
âœ… test_system_question()    # DocumentaciÃ³n de software
âœ… test_technical_question() # Pregunta tÃ©cnica especÃ­fica
```

---

## ğŸ“Š Uso de la API

### POST /chat

**Esquema de Request (ChatRequest):**
```json
{
  "question": "string",              // REQUERIDO
  "categoria_equipo": "string",      // Opcional: impresora, balanza, etc.
  "tipo_documentacion": "string",    // Opcional: tecnica, sistema
  "sistema": "string",               // Opcional: nombre del sistema
  "subtipo": "string",               // Opcional: fiscal, no_fiscal, etc.
  "marca": "string",                 // Opcional: hasar, epson, toledo
  "modelo": "string"                 // Opcional: 320F, 2098, etc.
}
```

**Esquema de Response (ChatResponse):**
```json
{
  "answer": "string",
  "sources": [
    {
      "document": "string",
      "page": "integer"
    }
  ],
  "images": [],
  "used_rag": "boolean"
}
```

### Ejemplos de uso

#### 1. Saludo simple (sin RAG)

**Request:**
```json
{
  "question": "Hola"
}
```

**Response:**
```json
{
  "answer": "Â¡Hola! Soy el asistente de documentaciÃ³n tÃ©cnica. Â¿En quÃ© puedo ayudarte?",
  "sources": [],
  "images": [],
  "used_rag": false
}
```

#### 2. Pregunta tÃ©cnica especÃ­fica con filtros explÃ­citos

**Request:**
```json
{
  "question": "Â¿CÃ³mo cambio la IP?",
  "marca": "hasar",
  "modelo": "320F",
  "categoria_equipo": "impresora"
}
```

**Response:**
```json
{
  "answer": "Para cambiar la direcciÃ³n IP de la impresora Hasar 320F...",
  "sources": [
    {
      "document": "Impresora_Hasar_320F_Manual.pdf",
      "page": 45
    }
  ],
  "images": [],
  "used_rag": true
}
```

#### 3. Pregunta con inferencia automÃ¡tica de modelo

**Request:**
```json
{
  "question": "Â¿CÃ³mo cambiar IP en la tmt20?"
}
```

**Inferencia automÃ¡tica (Nivel 1 - model_inference.py):**
El sistema detecta "tmt20" normalizado y lo mapea a:
```python
{
  "marca": "epson",
  "modelo": "Impresora_NO_fiscal_Epson_TM-T20",
  "categoria_equipo": "impresora"
}
```

Luego busca documentaciÃ³n especÃ­fica de ese modelo.

#### 3b. Pregunta con inferencia de sistema

**Request:**
```json
{
  "question": "Â¿CÃ³mo realizar cierre Z en StarPOS Market?"
}
```

**Inferencia automÃ¡tica (Nivel 2 - infer_filters.py):**
```python
{
  "sistema": "StarPOSMarketManual",
  "tipo_documentacion": "sistema"
}
```

#### 4. Pregunta sin documentaciÃ³n disponible

**Request:**
```json
{
  "question": "Â¿QuÃ© mantenimientos necesita una impresora fiscal?",
  "categoria_equipo": "impresora",
  "subtipo": "fiscal"
}
```

Si no hay documentaciÃ³n especÃ­fica en la base de datos para esta consulta genÃ©rica, el sistema:
- Intenta buscar en la documentaciÃ³n disponible
- Si no encuentra suficiente informaciÃ³n relevante, informa que no tiene documentaciÃ³n especÃ­fica

#### 5. Pregunta sobre sistema de software

**Request:**
```json
{
  "question": "Â¿CÃ³mo agregar un producto al sistema StarPOS?",
  "tipo_documentacion": "sistema",
  "sistema": "StarPOSMarketManual"
}
```

#### 6. Pregunta fuera de alcance

**Request:**
```json
{
  "question": "Â¿CuÃ¡l es la capital de Francia?"
}
```

**Response:**
```json
{
  "answer": "Lo siento, solo puedo responder consultas relacionadas con documentaciÃ³n tÃ©cnica y sistemas internos.",
  "sources": [],
  "images": [],
  "used_rag": false
}
```

---

## ğŸ” Flujo de Procesamiento Detallado (Optimizado)

### Flujo Completo

```
1. USER â†’ POST /chat
2. chat_router.py recibe request
3. âœ… Guardrails pre-LLM
4. ChatService.handle_question()
5. LangGraph ejecuta el grafo
6. classify_intent
   â”œâ”€ greeting â†’ conversational_node (sin RAG, sin inferencia)
   â”œâ”€ out_of_scope â†’ out_of_scope_node (sin RAG, sin inferencia)
   â””â”€ documentation â†’ documentation_node
       â”œâ”€ ğŸ” AQUÃ SE INFIEREN FILTROS (solo si es necesario)
       â”œâ”€ Merge con filtros explÃ­citos
       â”œâ”€ Pipeline RAG completo
       â””â”€ Retorna respuesta + filtros finales
7. Guardar historial (con filtros finales)
8. Retornar respuesta al usuario
```

### 1. Guardrails Pre-LLM

Antes de enviar al LLM, se valida que la consulta no contenga patrones prohibidos:

```python
# app/guardrails/pre_llm.py
forbidden_patterns = [
    "ignora", "ignorÃ¡", "evadir",
    "respondÃ© en inglÃ©s", "emojis",
    "mezclÃ¡", "usa conocimiento general"
]
```

Si se detecta, retorna mensaje de rechazo sin procesar.

### 2. ClasificaciÃ³n de Intenciones

```python
# classify_intent node (LangGraph)
Input: "Hola, Â¿cÃ³mo estÃ¡s?"
    â†“
LLM (temp=0.0) â†’ "greeting"
    â†“
Router â†’ conversational_node (âœ… NO infiere filtros)
```

**Tipos de intenciÃ³n:**
- `greeting`: Saludos, despedidas â†’ respuesta directa (SIN inferencia de filtros)
- `documentation`: Consultas tÃ©cnicas â†’ pipeline RAG (CON inferencia de filtros)
- `out_of_scope`: Fuera del dominio â†’ rechazo educado (SIN inferencia de filtros)

### 3. Inferencia y Merge de Filtros (SOLO en documentation_node)

**âš¡ OPTIMIZACIÃ“N:** Los filtros solo se infieren si `intent === "documentation"`

**Sistema de Inferencia de Filtros (Dos Niveles):**

**Nivel 1 - Inferencia de Modelos EspecÃ­ficos** (`model_inference.py` en el router):
- Detecta aliases de modelos en la pregunta:
  - "smhpt250f" â†’ `{marca: "hasar", modelo: "Impresora_fiscal_Hasar_SMH-PT-250F", subtipo: "fiscal"}`
  - "smhp441f" â†’ `{marca: "hasar", modelo: "Impresora_fiscal_Hasar_SMH-P-441F", subtipo: "fiscal"}`
  - "tmt20" â†’ `{marca: "epson", modelo: "Impresora_NO_fiscal_Epson_TM-T20"}`
- Se ejecuta ANTES de pasar al ChatService
- Normaliza texto removiendo caracteres especiales para mejor matching

**Nivel 2 - Inferencia General** (`infer_filters.py` en documentation_node):
- `categoria_equipo`: Detecta "impresora", "balanza" en la pregunta
- `tipo_documentacion`: 
  - "sistema" si detecta palabras como "configurar", "instalar", "usar", "cargar", "cierre"
  - "tecnica" si detecta "especificaciones", "caracterÃ­sticas", "tecnicas"
- `sistema`: Detecta nombres predefinidos usando diccionario con regex flexible:
  - "starpos", "star pos", "starpos market" â†’ "StarPOSMarketManual"
  - "backupmaster", "backup master" â†’ "BackupMaster"
  - "cloudsync", "cloud sync" â†’ "CloudSync"
  - "datavault", "data vault" â†’ "DataVault"

**Prioridad de Merge:**
Los filtros explÃ­citos del frontend tienen prioridad absoluta. Los inferidos solo se usan si el filtro correspondiente estÃ¡ vacÃ­o (`None`).

```python
# Solo se ejecuta dentro de documentation_node

# 1. Filtros explÃ­citos (del frontend)
explicit = {
    "marca": "hasar",
    "modelo": "320F"
}

# 2. Filtros inferidos de la pregunta
# Pregunta: "Â¿CÃ³mo realizar un cierre Z en StarPOS Market?"
inferred = infer_filters_from_question(pregunta)
# â†’ { 
#     "tipo_documentacion": "sistema",      (por "cierre")
#     "sistema": "StarPOSMarketManual"      (por "starpos market")
# }

# 3. Merge (explÃ­citos tienen prioridad)
final = merge_filters(explicit, inferred)
# â†’ { "marca": "hasar", "modelo": "320F", "tipo_documentacion": "sistema" }
```

### 4. Pipeline RAG (documentation_node)

**a) Query Rewriting:**
```python
# Enriquece la query con contexto
"Â¿CÃ³mo cambiar IP?"
    â†“
"Â¿CÃ³mo cambiar IP? hasar 320F"
```

**b) Retrieve:**
```python
# app/rag/retriever.py
- Embedding de query con Cohere Embed v3
- BÃºsqueda en ChromaDB con filtros de metadata
- Post-filtrado estricto por modelo (si aplica)
- Top 10-30 chunks (variable segÃºn tipo de doc)
```

**c) ValidaciÃ³n y Filtrado:**
```python
# app/utils/rag_validation.py
if modelo:
    chunks = filter_chunks_by_model(chunks, modelo)
if sistema:
    chunks = filter_chunks_by_system(chunks, sistema)
```

**d) Rerank:**
```python
# app/rag/reranker.py
- Cohere Rerank v4
- Relevance score
- Top 5 chunks finales
```

**e) Generate:**
```python
# app/rag/generator.py
- SelecciÃ³n de prompt (genÃ©rico vs especÃ­fico)
- Formateo del contexto
- GeneraciÃ³n con Cohere Command-R+
- ExtracciÃ³n de fuentes (documento + pÃ¡gina)
```

### 5. Persistencia del Historial

```python
# app/services/history_service.py
history_service.save_interaction(
    db=db,
    question=question,
    answer=answer
)
```

Guarda en tabla `history` de SQLite.

---

## ğŸ¯ CaracterÃ­sticas Avanzadas

### Prompts DinÃ¡micos

El sistema utiliza **2 tipos de prompts** segÃºn el contexto:

**1. Prompt EspecÃ­fico** (`rag_prompt.txt`)
- Usado cuando hay marca + modelo explÃ­cito
- Incluye variables `{marca}` y `{modelo}` en el contexto
- Respuestas altamente especÃ­ficas al equipo

**2. Prompt GenÃ©rico** (`rag_prompt_generic.txt`)
- Usado para consultas de categorÃ­a sin modelo
- Respuestas generales sobre tipos de equipos
- Ej: "Â¿QuÃ© mantenimientos necesita una impresora fiscal?"

### Filtrado Estricto por Modelo

```python
# Triple validaciÃ³n de modelo:
1. WHERE clause en ChromaDB
2. Post-filtro en retriever.py
3. ValidaciÃ³n final en generator.py
```

Garantiza que NUNCA se mezcle informaciÃ³n de modelos diferentes.

### Fallback para DocumentaciÃ³n de Sistemas

```python
if tipo_doc == "sistema" and len(chunks) < 5:
    # Ampliar bÃºsqueda
    chunks = retriever.retrieve(top_k=30)
```

Los manuales de software tienen estructura diferente, por lo que se permite mayor cantidad de chunks para capturar contexto completo.

### ValidaciÃ³n de Modelo Ãšnico

```python
# app/utils/rag_validation.py
def validate_single_model(chunks):
    modelos = {c["metadata"].get("modelo") for c in chunks}
    if len(modelos) > 1:
        # Retorna solo el modelo mÃ¡s frecuente
```

Evita contaminaciÃ³n cruzada entre modelos similares.

---

## ğŸ“‚ Metadata de Documentos

### Estructura de Metadata

Cada chunk en ChromaDB tiene la siguiente metadata:

```python
{
    "document": "Impresora_Hasar_320F_Manual.pdf",
    "page": 12,
    "categoria_equipo": "impresora",
    "tipo_documentacion": "tecnica",
    "subtipo": "fiscal",
    "marca": "hasar",
    "modelo": "320F",           # Solo docs tÃ©cnicos
    "sistema": None             # Solo docs de software
}
```

### Inferencia AutomÃ¡tica

La metadata se infiere automÃ¡ticamente del nombre del archivo durante la ingesta:

```python
# app/metadata/infer.py
"Impresora_Hasar_320F_Manual.pdf"
    â†“
{
    "categoria_equipo": "impresora",
    "marca": "hasar",
    "modelo": "320F",
    "subtipo": "fiscal"  # si contiene "fiscal" en el nombre
}
```

---

## ğŸ—„ï¸ Base de Datos

### Tablas SQLAlchemy

**History**
```python
# app/models/history_model.py
- id: Integer (PK)
- question: Text
- answer: Text
- created_at: DateTime
- tipo_documentacion: String (nullable)
- sistema: String (nullable)
- subtipo: String (nullable)
- marca: String (nullable)
- modelo: String (nullable)
```

Estos campos adicionales se agregaron para almacenar metadata de cada consulta.

### InicializaciÃ³n

```bash
# Crear tablas
python -m app.db.init_db
```

---

## ğŸ› ï¸ Scripts de Utilidad

### Ingesta de Documentos

```bash
python -m app.vectorstore.ingest
```

Procesa todos los PDFs en `data/pdfs/` y los almacena en ChromaDB.

**CaracterÃ­sticas:**
- Procesa pÃ¡ginas completas de cada PDF
- Chunking inteligente con overlapping
- Rate limiting para evitar errores de API
- Batch processing (10 chunks a la vez)

### Debug del Retriever

```bash
python -m app.debug.test_retriever
```

Permite probar el retriever con queries especÃ­ficas.

### Debug del Grafo

```bash
python -m app.debug.test_graph
```

Prueba el flujo completo del LangGraph con una pregunta de ejemplo.

---

## ğŸ“‹ Variables de Entorno

```env
# .env
COHERE_API_KEY=tu_api_key_aqui
```

**Nota:** No se necesitan otras variables de configuraciÃ³n. El proyecto usa SQLite local y ChromaDB persistente en disco.


---

## ğŸ¯ Requisitos del Challenge (Cumplimiento)

### Requisitos Obligatorios

| Requisito | Estado | ImplementaciÃ³n |
|-----------|--------|----------------|
| Funcionamiento completo end-to-end | âœ… | Pipeline completo |
| API REST | âœ… | FastAPI + Swagger |
| 3+ preguntas test | âœ… | 4 tests unitarios |
| >100k caracteres | âœ… | ~187k caracteres |
| Vector DB persistente | âœ… | ChromaDB precargada |
| Solo temas pertinentes | âœ… | `out_of_scope_node` |
| Sin emojis | âœ… | Validado en prompts |
| Siempre espaÃ±ol | âœ… | Forzado en prompts |
| Respuestas consistentes | âœ… | Sin temperatura aleatoria |

### Innovaciones Implementadas

| InnovaciÃ³n | ImplementaciÃ³n |
|-----------|----------------|
| âœ… Reranking | Cohere Rerank v4 |
| âœ… Historial | SQLite + SQLAlchemy |
| âœ… Orquestador LLM | LangGraph con classify_intent |
| âœ… Framework IA | LangGraph |
| âœ… Metadata avanzada | Filtros multi-criterio en ChromaDB |
| âœ… TÃ©cnicas avanzadas | Inferencia automÃ¡tica de filtros |

---

## ğŸ”§ Troubleshooting

### Error: "No module named 'cohere'"
```bash
pip install cohere
```

### Error: ChromaDB no encuentra documentos
```bash
# Re-ejecutar ingesta
python -m app.vectorstore.ingest
```

### Error: "Invalid API key"
Verificar que `.env` tenga tu Cohere API key vÃ¡lida

### API responde lento
- Primera llamada siempre es mÃ¡s lenta (cold start de Cohere)
- Siguientes llamadas ~2-3 segundos

---

## ğŸš€ Mejoras Futuras

- [ ] Fine-tuning de embeddings para dominio especÃ­fico
- [ ] BÃºsqueda hÃ­brida (semÃ¡ntica + keywords BM25)
- [ ] Feedback loop (ğŸ‘/ğŸ‘ para mejorar prompts)
- [ ] Multi-idioma (inglÃ©s, portuguÃ©s)
- [ ] IntegraciÃ³n con APIs externas (stock, precios)
- [ ] Dashboard de analytics del historial
- [ ] Cache de respuestas frecuentes
- [ ] Multi-tenancy para mÃºltiples empresas

---


## ğŸ‘¤ Autor

**Agostina Torres**  
Get Talent - Pi Data  
Challenge Final - Diciembre 2025

---

